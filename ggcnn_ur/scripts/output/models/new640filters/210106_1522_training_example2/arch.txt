----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 16, 300, 300]           1,952
              ReLU-2         [-1, 16, 300, 300]               0
            Conv2d-3         [-1, 16, 300, 300]           6,416
              ReLU-4         [-1, 16, 300, 300]               0
         MaxPool2d-5         [-1, 16, 150, 150]               0
            Conv2d-6         [-1, 16, 150, 150]           6,416
              ReLU-7         [-1, 16, 150, 150]               0
            Conv2d-8         [-1, 16, 150, 150]           6,416
              ReLU-9         [-1, 16, 150, 150]               0
        MaxPool2d-10           [-1, 16, 75, 75]               0
           Conv2d-11           [-1, 32, 75, 75]          12,832
             ReLU-12           [-1, 32, 75, 75]               0
           Conv2d-13           [-1, 32, 75, 75]          25,632
             ReLU-14           [-1, 32, 75, 75]               0
UpsamplingBilinear2d-15         [-1, 32, 150, 150]               0
           Conv2d-16         [-1, 16, 150, 150]           4,624
             ReLU-17         [-1, 16, 150, 150]               0
UpsamplingBilinear2d-18         [-1, 16, 300, 300]               0
           Conv2d-19         [-1, 16, 300, 300]           2,320
             ReLU-20         [-1, 16, 300, 300]               0
           Conv2d-21          [-1, 1, 300, 300]              17
           Conv2d-22          [-1, 1, 300, 300]              17
           Conv2d-23          [-1, 1, 300, 300]              17
           Conv2d-24          [-1, 1, 300, 300]              17
================================================================
Total params: 66,676
Trainable params: 66,676
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 110.55
Params size (MB): 0.25
Estimated Total Size (MB): 111.15
----------------------------------------------------------------

python train_ggcnn.py --description training_example2 --network ggcnn2 --dataset cornell --dataset-path ./mydataset640filters/ --batches-per-epoch 500 --use-rgb 0


INFO:root:Beginning Epoch 00
INFO:root:Epoch: 0, Batch: 100, Loss: 0.0731
INFO:root:Epoch: 0, Batch: 200, Loss: 0.0669
INFO:root:Epoch: 0, Batch: 300, Loss: 0.0574
INFO:root:Epoch: 0, Batch: 400, Loss: 0.0497
INFO:root:Validating...
INFO:root:83/249 = 0.333333
INFO:root:Beginning Epoch 01
INFO:root:Epoch: 1, Batch: 100, Loss: 0.0298
INFO:root:Epoch: 1, Batch: 200, Loss: 0.0357
INFO:root:Epoch: 1, Batch: 300, Loss: 0.0319
INFO:root:Epoch: 1, Batch: 400, Loss: 0.0407
INFO:root:Validating...
INFO:root:225/249 = 0.903614
INFO:root:Beginning Epoch 02
INFO:root:Epoch: 2, Batch: 100, Loss: 0.0247
INFO:root:Epoch: 2, Batch: 200, Loss: 0.0327
INFO:root:Epoch: 2, Batch: 300, Loss: 0.0329
INFO:root:Epoch: 2, Batch: 400, Loss: 0.0218
INFO:root:Validating...
INFO:root:249/249 = 1.000000
INFO:root:Beginning Epoch 03
INFO:root:Epoch: 3, Batch: 100, Loss: 0.0425
INFO:root:Epoch: 3, Batch: 200, Loss: 0.0284
INFO:root:Epoch: 3, Batch: 300, Loss: 0.0440
INFO:root:Epoch: 3, Batch: 400, Loss: 0.0269
INFO:root:Validating...
INFO:root:249/249 = 1.000000
INFO:root:Beginning Epoch 04
INFO:root:Epoch: 4, Batch: 100, Loss: 0.0306
INFO:root:Epoch: 4, Batch: 200, Loss: 0.0194
INFO:root:Epoch: 4, Batch: 300, Loss: 0.0283
INFO:root:Epoch: 4, Batch: 400, Loss: 0.0264
INFO:root:Validating...
INFO:root:249/249 = 1.000000
INFO:root:Beginning Epoch 05
INFO:root:Epoch: 5, Batch: 100, Loss: 0.0255
INFO:root:Epoch: 5, Batch: 200, Loss: 0.0224
INFO:root:Epoch: 5, Batch: 300, Loss: 0.0258

